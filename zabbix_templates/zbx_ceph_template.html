<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<style type="text/css">

   p.desc{
     white-space:nowrap;
   }

   table.pretty {
    margin: 1em 1em 1em 2em;
    background: whitesmoke;
    border-collapse: collapse;
   }

   table.pretty th, table.pretty td {
    border: 1px gainsboro solid;
    padding: 0.2em;
   }

   table.pretty th {
    background: gainsboro;
    text-align: left;
   }

   table.pretty caption {
    margin-left: inherit;
    margin-right: inherit;
    white-space:nowrap;
   }
  </style>
<body>
<h2>Macro Overview</h2>

  The following macros can be overloaded on host level.
  <table class="pretty">
<tr>
<th>Name</th><th>Default</th>
</tr>
<tr>
<td>{$CLUSTER_NAME}</td><td>ceph</td>
</tr>
<tr>
<td>{$FULLRATIO}</td><td>95</td>
</tr>
<tr>
<td>{$SPACEAVAIL_AVERAGE}</td><td>0.1</td>
</tr>
<tr>
<td>{$SPACEAVAIL_HIGH}</td><td>0.05</td>
</tr>
<tr>
<td>{$SPACEAVAIL_POOL_HIGH}</td><td>10</td>
</tr>
<tr>
<td>{$SPACEAVAIL_WARNING}</td><td>0.2</td>
</tr>
</table>
<h1>Static Elements</h1>
<h2>Trigger Overview</h2>
<table class="pretty">
<tr>
<th>Name</th><th>Description</th><th>Priority</th><th>Expression</th><th>Dependencies</th>
</tr>
<tr>
<td>Ceph cluster has degraded PGs</td><td>Ceph has not replicated some objects in the placement group the correct number of times yet.</td><td style="background-color:#FFFF00;">Warning</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.degraded.last(0)}&gt;0</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph cluster has down PGs</td><td>At least a replica with necessary data is down, so the placement group is offline.</td><td style="background-color:#FF0000;">Average</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.down.last(0)}&gt;0</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph cluster in ERROR state</td><td></td><td style="background-color:#FF0000;">Disaster</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.health.str("HEALTH_ERROR")}=1</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph cluster in WARN state</td><td></td><td style="background-color:#FF0000;">High</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.health.str("HEALTH_WARN")}=1</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph cluster is not OK</td><td></td><td style="background-color:#FF0000;">Average</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.health.str("HEALTH_OK")}&lt;&gt;1</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph cluster monitoring not data for 900s</td><td></td><td style="background-color:#FF0000;">Average</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.health.nodata(900)}=1</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph Cluster SpaceAvail is less than 5%</td><td></td><td style="background-color:#FF0000;">High</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.spaceavail.last()}/{Custom - Service - Ceph Storage - Extended:ceph.spacetotal.last()}&lt;{$SPACEAVAIL_HIGH}</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph Cluster SpaceAvail is less than 10%</td><td></td><td style="background-color:#FF0000;">Average</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.spaceavail.last()}/{Custom - Service - Ceph Storage - Extended:ceph.spacetotal.last()}&lt;{$SPACEAVAIL_AVERAGE}</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph Cluster SpaceAvail is less than 15%</td><td></td><td style="background-color:#FFFF00;">Warning</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.spaceavail.last()}/{Custom - Service - Ceph Storage - Extended:ceph.spacetotal.last()}&lt;{$SPACEAVAIL_WARNING}</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph Cluster Space timeleft is less than a day</td><td></td><td style="background-color:#FF0000;">High</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.spaceavail.timeleft(86400,,0)}&lt;1h</tt></td><td><tt>Ceph Cluster Space timeleft is less than a hour<br>
</tt></td>
</tr>
<tr>
<td>Ceph Cluster Space timeleft is less than a hour</td><td></td><td style="background-color:#FF0000;">Disaster</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.spaceavail.timeleft(3600,,0)}&lt;1h</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph Cluster Space timeleft is less than a week</td><td></td><td style="background-color:#FFFF00;">Warning</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.spaceavail.timeleft(604800,,0)}&lt;1w</tt></td><td><tt>Ceph Cluster Space timeleft is less than a hour<br>Ceph Cluster Used Space will reach FullRatio Mark less than in a day<br>
</tt></td>
</tr>
<tr>
<td>Ceph Cluster Space timeleft is less than a week</td><td></td><td style="background-color:#FFFF00;">Information</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.spaceavail.timeleft(2592000,,0)}&lt;30d</tt></td><td><tt>Ceph Cluster Space timeleft is less than a hour<br>Ceph Cluster Space timeleft is less than a week<br>Ceph Cluster Used Space will reach FullRatio Mark less than in a day<br>
</tt></td>
</tr>
<tr>
<td>Ceph Cluster Used Space will reach FullRatio Mark less than in a day</td><td></td><td style="background-color:#FF0000;">High</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.fullratio.timeleft(86400,,0)}&lt;1d</tt></td><td><tt>Ceph Cluster Used Space will reach FullRatio Mark less than in an hour<br>
</tt></td>
</tr>
<tr>
<td>Ceph Cluster Used Space will reach FullRatio Mark less than in an hour</td><td></td><td style="background-color:#FF0000;">Disaster</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.fullratio.timeleft(3600,,0)}&lt;1h</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph Cluster Used Space will reach FullRatio Mark less than in a week</td><td></td><td style="background-color:#FFFF00;">Warning</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.fullratio.timeleft(604800,,0)}&lt;1w</tt></td><td><tt>Ceph Cluster Used Space will reach FullRatio Mark less than in a day<br>Ceph Cluster Used Space will reach FullRatio Mark less than in an hour<br>
</tt></td>
</tr>
<tr>
<td>Ceph Cluster Used Space will reach NearFullRatio Mark less than in a day</td><td></td><td style="background-color:#FF0000;">High</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.nearfullratio.timeleft(86400,,0)}&lt;1d</tt></td><td><tt>Ceph Cluster Used Space will reach NearFullRatio Mark less than in an hour<br>
</tt></td>
</tr>
<tr>
<td>Ceph Cluster Used Space will reach NearFullRatio Mark less than in a month</td><td></td><td style="background-color:#FFFF00;">Information</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.nearfullratio.timeleft(2592000,,0)}&lt;30d</tt></td><td><tt>Ceph Cluster Used Space will reach NearFullRatio Mark less than in a day<br>Ceph Cluster Used Space will reach NearFullRatio Mark less than in an hour<br>Ceph Cluster Used Space will reach NearFullRatio Mark less than in a week<br>
</tt></td>
</tr>
<tr>
<td>Ceph Cluster Used Space will reach NearFullRatio Mark less than in an hour</td><td></td><td style="background-color:#FF0000;">Disaster</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.nearfullratio.timeleft(3600,,0)}&lt;1h</tt></td><td><tt></tt></td>
</tr>
<tr>
<td>Ceph Cluster Used Space will reach NearFullRatio Mark less than in a week</td><td></td><td style="background-color:#FFFF00;">Warning</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.nearfullratio.timeleft(604800,,0)}&lt;1w</tt></td><td><tt>Ceph Cluster Used Space will reach NearFullRatio Mark less than in a day<br>Ceph Cluster Used Space will reach NearFullRatio Mark less than in an hour<br>
</tt></td>
</tr>
</table>
<h2>Graph Overview</h2>
<table class="pretty">
<tr>
<th>Name</th><th>Elements</th>
</tr>
<tr>
<td>Ceph Load</td><td><tt>ceph.rdbps<br>ceph.wrbps<br>ceph.opsread<br>
</tt></td>
</tr>
<tr>
<td>Degraded %</td><td><tt>ceph.degraded_percent<br>
</tt></td>
</tr>
<tr>
<td>Moving PGs</td><td><tt>ceph.recovering<br>ceph.remapped<br>ceph.peering<br>
</tt></td>
</tr>
<tr>
<td>OSDs</td><td><tt>ceph.osd_up<br>ceph.osd_in<br>
</tt></td>
</tr>
<tr>
<td>PGS</td><td><tt>ceph.active<br>ceph.clean<br>
</tt></td>
</tr>
<tr>
<td>Problem PGs</td><td><tt>ceph.degraded<br>ceph.incomplete<br>ceph.inconsistent<br>ceph.down<br>
</tt></td>
</tr>
</table>
<h2>Item Overview</h2>
<table class="pretty">
<tr>
<th>Type</th><th>Name</th><th>Key</th><th>Description</th><th>Interval (sec)</th><th>History Days</th><th>Trend Days</th>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG activating</td><td><tt>ceph.activating</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG active</td><td><tt>ceph.active</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG backfilling</td><td><tt>ceph.backfilling</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG backfill_toofull</td><td><tt>ceph.backfill_toofull</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG backfill_unfound</td><td><tt>ceph.backfill_unfound</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG wait-backfill</td><td><tt>ceph.backfill_wait</tt></td><td>The placement group is waiting in line to start backfill.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG clean</td><td><tt>ceph.clean</tt></td><td>Ceph replicated all objects in the placement group the correct number of times.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG creating</td><td><tt>ceph.creating</tt></td><td>Ceph is still creating the placement group.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG deep</td><td><tt>ceph.deep</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG degraded</td><td><tt>ceph.degraded</tt></td><td>Ceph has not replicated some objects in the placement group the correct number of times yet.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Calculated</p>
</td><td>Ceph PG degraded %</td><td><tt>ceph.degraded_percent</tt></td><td>Ceph has not replicated some objects in the placement group the correct number of times yet.</td><td>30</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG down</td><td><tt>ceph.down</tt></td><td>A replica with necessary data is down, so the placement group is offline.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG forced_backfill</td><td><tt>ceph.forced_backfill</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG forced_recovery</td><td><tt>ceph.forced_recovery</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Calculated</p>
</td><td>Ceph Full Ratio Space</td><td><tt>ceph.fullratio</tt></td><td>http://docs.ceph.com/docs/master/rados/troubleshooting/troubleshooting-osd/&#13;
NO FREE DRIVE SPACE&#13;
&#13;
Ceph prevents you from writing to a full OSD so that you don&rsquo;t lose data. In an operational cluster, you should receive a warning when your cluster is getting near its full ratio. The mon osd full ratio defaults to 0.95, or 95% of capacity before it stops clients from writing data. The mon osd nearfull ratio defaults to 0.85, or 85% of capacity when it generates a health warning.&#13;
&#13;
Full cluster issues usually arise when testing how Ceph handles an OSD failure on a small cluster. When one node has a high percentage of the cluster&rsquo;s data, the cluster can easily eclipse its nearfull and full ratio immediately. If you are testing how Ceph reacts to OSD failures on a small cluster, you should leave ample free disk space and consider temporarily lowering the mon osd full ratio and mon osd nearfull ratio.</td><td>5m</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Calculated</p>
</td><td>Ceph Full Ratio %</td><td><tt>ceph.fullratioprcnt</tt></td><td>http://docs.ceph.com/docs/master/rados/troubleshooting/troubleshooting-osd/&#13;
NO FREE DRIVE SPACE&#13;
&#13;
Ceph prevents you from writing to a full OSD so that you don&rsquo;t lose data. In an operational cluster, you should receive a warning when your cluster is getting near its full ratio. The mon osd full ratio defaults to 0.95, or 95% of capacity before it stops clients from writing data. The mon osd nearfull ratio defaults to 0.85, or 85% of capacity when it generates a health warning.&#13;
&#13;
Full cluster issues usually arise when testing how Ceph handles an OSD failure on a small cluster. When one node has a high percentage of the cluster&rsquo;s data, the cluster can easily eclipse its nearfull and full ratio immediately. If you are testing how Ceph reacts to OSD failures on a small cluster, you should leave ample free disk space and consider temporarily lowering the mon osd full ratio and mon osd nearfull ratio.</td><td>5m</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph Cluster health</td><td><tt>ceph.health</tt></td><td>HEALTH_OK: 1&#13;
HEALTH_WARN: 2&#13;
HEALTH_ERR: 0</td><td>0</td><td>60d</td><td>0</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph Cluster health overall_status</td><td><tt>ceph.health.overall_status</tt></td><td>HEALTH_OK: 1&#13;
HEALTH_WARN: 2&#13;
HEALTH_ERR: 0</td><td>0</td><td>60d</td><td>0</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG incomplete</td><td><tt>ceph.incomplete</tt></td><td>Ceph detects that a placement group is missing a necessary period of history from its log. If you see this state, report a bug, and try to start any failed OSDs that may contain the needed information.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG inconsistent</td><td><tt>ceph.inconsistent</tt></td><td>Ceph detects inconsistencies in the one or more replicas of an object in the placement group (e.g. objects are the wrong size, objects are missing from one replica after recovery finished, etc.).</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph MON Count</td><td><tt>ceph.moncount</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Calculated</p>
</td><td>Ceph NearFull Ratio Space</td><td><tt>ceph.nearfullratio</tt></td><td>http://docs.ceph.com/docs/master/rados/troubleshooting/troubleshooting-osd/&#13;
NO FREE DRIVE SPACE&#13;
&#13;
Ceph prevents you from writing to a full OSD so that you don&rsquo;t lose data. In an operational cluster, you should receive a warning when your cluster is getting near its full ratio. The mon osd full ratio defaults to 0.95, or 95% of capacity before it stops clients from writing data. The mon osd nearfull ratio defaults to 0.85, or 85% of capacity when it generates a health warning.&#13;
&#13;
Full cluster issues usually arise when testing how Ceph handles an OSD failure on a small cluster. When one node has a high percentage of the cluster&rsquo;s data, the cluster can easily eclipse its nearfull and full ratio immediately. If you are testing how Ceph reacts to OSD failures on a small cluster, you should leave ample free disk space and consider temporarily lowering the mon osd full ratio and mon osd nearfull ratio.</td><td>5m</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Calculated</p>
</td><td>Ceph NearFull Ratio %</td><td><tt>ceph.nearfullratioprcnt</tt></td><td>http://docs.ceph.com/docs/master/rados/troubleshooting/troubleshooting-osd/&#13;
NO FREE DRIVE SPACE&#13;
&#13;
Ceph prevents you from writing to a full OSD so that you don&rsquo;t lose data. In an operational cluster, you should receive a warning when your cluster is getting near its full ratio. The mon osd full ratio defaults to 0.95, or 95% of capacity before it stops clients from writing data. The mon osd nearfull ratio defaults to 0.85, or 85% of capacity when it generates a health warning.&#13;
&#13;
Full cluster issues usually arise when testing how Ceph handles an OSD failure on a small cluster. When one node has a high percentage of the cluster&rsquo;s data, the cluster can easily eclipse its nearfull and full ratio immediately. If you are testing how Ceph reacts to OSD failures on a small cluster, you should leave ample free disk space and consider temporarily lowering the mon osd full ratio and mon osd nearfull ratio.</td><td>5m</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph OSD in</td><td><tt>ceph.num_in_osds</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph OSD up</td><td><tt>ceph.num_up_osds</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph Operation Read</td><td><tt>ceph.opsread</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph Operation Write</td><td><tt>ceph.opswrite</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph OSD Count</td><td><tt>ceph.osdcount</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Calculated</p>
</td><td>Ceph OSD in %</td><td><tt>ceph.osd_in</tt></td><td></td><td>30</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Calculated</p>
</td><td>Ceph OSD up %</td><td><tt>ceph.osd_up</tt></td><td></td><td>30</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG peered</td><td><tt>ceph.peered</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG peering</td><td><tt>ceph.peering</tt></td><td>The placement group is undergoing the peering process</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG total</td><td><tt>ceph.pgtotal</tt></td><td>Ceph total placement group number.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph Read Speed</td><td><tt>ceph.rdbps</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG recovering</td><td><tt>ceph.recovering</tt></td><td>Ceph is migrating/synchronizing objects and their replicas.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG recovery_toofull</td><td><tt>ceph.recovery_toofull</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG recovery_unfound</td><td><tt>ceph.recovery_unfound</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG recovery_wait</td><td><tt>ceph.recovery_wait</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG remapped</td><td><tt>ceph.remapped</tt></td><td>The placement group is temporarily mapped to a different set of OSDs from what CRUSH specified.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG repair</td><td><tt>ceph.repair</tt></td><td>Ceph is checking the placement group and repairing any inconsistencies it finds (if possible).</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG scrubbing</td><td><tt>ceph.scrubbing</tt></td><td>Ceph is checking the placement group for inconsistencies.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG snaptrim</td><td><tt>ceph.snaptrim</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG snaptrim_error</td><td><tt>ceph.snaptrim_error</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG snaptrim_wait</td><td><tt>ceph.snaptrim_wait</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph Space Available</td><td><tt>ceph.spaceavail</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph Space Total</td><td><tt>ceph.spacetotal</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Calculated</p>
</td><td>Ceph Space Used</td><td><tt>ceph.spaceused</tt></td><td></td><td>5m</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG stale</td><td><tt>ceph.stale</tt></td><td>The placement group is in an unknown state - the monitors have not received an update for it since the placement group mapping changed.</td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph PG undersized</td><td><tt>ceph.undersized</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Ceph Write Speed</td><td><tt>ceph.wrbps</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
</table>
<h1>Discovery rule "MON"</h1>
<table class="pretty">
<tr>
<th>Name</th><th>Value</th>
</tr>
<tr>
<td>Name</td><td>MON</td>
</tr>
<tr>
<td>Key</td><td>ceph-mon-discovery[mons]</td>
</tr>
<tr>
<td>Type</td><td>
<p class="desc">Zabbix Trapper</p>
</td>
</tr>
<tr>
<td>Delay</td><td>0</td>
</tr>
</table>
<h2>Trigger Overview</h2>
<table class="pretty">
<tr>
<th>Name</th><th>Description</th><th>Priority</th><th>Expression</th><th>Dependencies</th>
</tr>
</table>
<h2>Graph Overview</h2>
<table class="pretty">
<tr>
<th>Name</th><th>Elements</th>
</tr>
</table>
<h2>Item Overview</h2>
<table class="pretty">
<tr>
<th>Type</th><th>Name</th><th>Key</th><th>Description</th><th>Interval (sec)</th><th>History Days</th><th>Trend Days</th>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>{#MON}: Status</td><td><tt>ceph.monstatus[{#MON}]</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
</table>
<h1>Discovery rule "OSD"</h1>
<table class="pretty">
<tr>
<th>Name</th><th>Value</th>
</tr>
<tr>
<td>Name</td><td>OSD</td>
</tr>
<tr>
<td>Key</td><td>ceph-osd-discovery[osds]</td>
</tr>
<tr>
<td>Type</td><td>
<p class="desc">Zabbix Trapper</p>
</td>
</tr>
<tr>
<td>Delay</td><td>0</td>
</tr>
</table>
<h2>Trigger Overview</h2>
<table class="pretty">
<tr>
<th>Name</th><th>Description</th><th>Priority</th><th>Expression</th><th>Dependencies</th>
</tr>
</table>
<h2>Graph Overview</h2>
<table class="pretty">
<tr>
<th>Name</th><th>Elements</th>
</tr>
<tr>
<td>{#OSD} : Latencies ({#DEVICECLASS})</td><td><tt>ceph.osdperf[{#OSD},commit_latency_ms]<br>ceph.osdperf[{#OSD},apply_latency_ms]<br>
</tt></td>
</tr>
<tr>
<td>{#OSD} : Space Available ({#DEVICECLASS})</td><td><tt>ceph.osdspaceavail[{#OSD}]<br>
</tt></td>
</tr>
</table>
<h2>Item Overview</h2>
<table class="pretty">
<tr>
<th>Type</th><th>Name</th><th>Key</th><th>Description</th><th>Interval (sec)</th><th>History Days</th><th>Trend Days</th>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>{#OSD} : Apply Latency ({#DEVICECLASS})</td><td><tt>ceph.osdperf[{#OSD},apply_latency_ms]</tt></td><td>Commit latency is how long it takes for an operation to be applied to&#13;
disk &mdash; generally speaking, how long it takes the journal to write an&#13;
entry. Apply latency is how long it takes to get applied to the&#13;
backing filesystem (which can be throttled by various things to&#13;
prevent us getting arbitrarily large amounts of dirty data).</td><td>0</td><td>7d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>{#OSD}: Commit Latency ({#DEVICECLASS})</td><td><tt>ceph.osdperf[{#OSD},commit_latency_ms]</tt></td><td>Commit latency is how long it takes for an operation to be applied to&#13;
disk &mdash; generally speaking, how long it takes the journal to write an&#13;
entry. Apply latency is how long it takes to get applied to the&#13;
backing filesystem (which can be throttled by various things to&#13;
prevent us getting arbitrarily large amounts of dirty data).</td><td>0</td><td>7d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>{#OSD} : Space Available ({#DEVICECLASS})</td><td><tt>ceph.osdspaceavail[{#OSD}]</tt></td><td></td><td>0</td><td>90d</td><td>365d</td>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>{#OSD}: Status ({#DEVICECLASS})</td><td><tt>ceph.osdstatus[{#OSD}]</tt></td><td></td><td>0</td><td>90d</td><td>365d</td>
</tr>
</table>
<h1>Discovery rule "POOL"</h1>
<table class="pretty">
<tr>
<th>Name</th><th>Value</th>
</tr>
<tr>
<td>Name</td><td>POOL</td>
</tr>
<tr>
<td>Key</td><td>ceph-pools-discovery[pools]</td>
</tr>
<tr>
<td>Type</td><td>
<p class="desc">Zabbix Trapper</p>
</td>
</tr>
<tr>
<td>Delay</td><td>0</td>
</tr>
</table>
<h2>Trigger Overview</h2>
<table class="pretty">
<tr>
<th>Name</th><th>Description</th><th>Priority</th><th>Expression</th><th>Dependencies</th>
</tr>
<tr>
<td>Ceph Cluster: {#POOL} : Space Available is less than {$SPACEAVAIL_POOL_HIGH}</td><td></td><td style="background-color:#FF0000;">High</td><td><tt>{Custom - Service - Ceph Storage - Extended:ceph.poolspaceavail[{#POOL}].last()}&lt;{$SPACEAVAIL_POOL_HIGH}</tt></td><td><tt></tt></td>
</tr>
</table>
<h2>Graph Overview</h2>
<table class="pretty">
<tr>
<th>Name</th><th>Elements</th>
</tr>
<tr>
<td>Space Available : {#POOL}</td><td><tt>ceph.poolspaceavail[{#POOL}]<br>
</tt></td>
</tr>
</table>
<h2>Item Overview</h2>
<table class="pretty">
<tr>
<th>Type</th><th>Name</th><th>Key</th><th>Description</th><th>Interval (sec)</th><th>History Days</th><th>Trend Days</th>
</tr>
<tr>
<td>
<p class="desc">Zabbix Trapper</p>
</td><td>Space Available : {#POOL}</td><td><tt>ceph.poolspaceavail[{#POOL}]</tt></td><td></td><td>0</td><td>14d</td><td>365d</td>
</tr>
</table>
</body>
</html>
